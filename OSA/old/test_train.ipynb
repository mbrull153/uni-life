{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CHECKING DATAFRAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = 'OSA_DB_UPM.xlsx'\n",
    "\n",
    "# Load spreadsheet\n",
    "xl = pd.ExcelFile(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Patient</th>\n",
       "      <th>Gender</th>\n",
       "      <th>IAH</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Height</th>\n",
       "      <th>Age</th>\n",
       "      <th>Cervical</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P0002</td>\n",
       "      <td>hombre</td>\n",
       "      <td>29.6</td>\n",
       "      <td>119</td>\n",
       "      <td>174</td>\n",
       "      <td>56</td>\n",
       "      <td>48.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P0004</td>\n",
       "      <td>hombre</td>\n",
       "      <td>19.7</td>\n",
       "      <td>78</td>\n",
       "      <td>168</td>\n",
       "      <td>39</td>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P0005</td>\n",
       "      <td>hombre</td>\n",
       "      <td>9.0</td>\n",
       "      <td>80</td>\n",
       "      <td>173</td>\n",
       "      <td>32</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>P0006</td>\n",
       "      <td>hombre</td>\n",
       "      <td>2.0</td>\n",
       "      <td>109</td>\n",
       "      <td>190</td>\n",
       "      <td>32</td>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>P0007</td>\n",
       "      <td>hombre</td>\n",
       "      <td>34.0</td>\n",
       "      <td>86</td>\n",
       "      <td>169</td>\n",
       "      <td>39</td>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Patient  Gender   IAH  Weight  Height  Age  Cervical\n",
       "0   P0002  hombre  29.6     119     174   56      48.0\n",
       "1   P0004  hombre  19.7      78     168   39      42.0\n",
       "2   P0005  hombre   9.0      80     173   32      40.0\n",
       "3   P0006  hombre   2.0     109     190   32      42.0\n",
       "4   P0007  hombre  34.0      86     169   39      42.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OSA_df = xl.parse('Sheet1')\n",
    "OSA_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "del OSA_df['Patient']\n",
    "del OSA_df['Gender']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 637 entries, 0 to 636\n",
      "Data columns (total 5 columns):\n",
      "IAH         637 non-null float64\n",
      "Weight      637 non-null int64\n",
      "Height      637 non-null int64\n",
      "Age         637 non-null int64\n",
      "Cervical    637 non-null float64\n",
      "dtypes: float64(2), int64(3)\n",
      "memory usage: 25.0 KB\n"
     ]
    }
   ],
   "source": [
    "OSA_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DEFINING DIFFERENT SPLITTING METHODS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To prevent Data Snooping Bias it is important to create a testing set early on in the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from zlib import crc32\n",
    "\n",
    "#Simple random test splitter\n",
    "#Creates a random Test Set. The Test Set will be ${test_ratio}% of the whole dataset. \n",
    "#Drawback: each execution will produce a different test set.\n",
    "def simple_random_test_splitter(data, test_ratio):\n",
    "    shuffled_indices = np.random.permutation(len(data))\n",
    "    test_set_size = int(len(data) * test_ratio)\n",
    "    test_indices = shuffled_indices[:test_set_size]\n",
    "    train_indices = shuffled_indices[test_set_size:]\n",
    "    return data.iloc[train_indices], data.iloc[test_indices]\n",
    "\n",
    "#Seed random test splitter.\n",
    "#Creates a random unique Test Set based on a seed. The Test Set will be ${test_ratio}% of the whole dataset.\n",
    "#Drawback: if new data is added to the dataset the test set won't be unique.\n",
    "def seed_random_test_splitter(data, test_ratio, seed):\n",
    "    #Use a seed in the random generator to split data always on the same indices.\n",
    "    np.random.seed(seed)\n",
    "    shuffled_indices = np.random.permutation(len(data))\n",
    "    test_set_size = int(len(data) * test_ratio)\n",
    "    test_indices = shuffled_indices[:test_set_size]\n",
    "    train_indices = shuffled_indices[test_set_size:]\n",
    "    return data.iloc[train_indices], data.iloc[test_indices]\n",
    "\n",
    "#Hash randon test splitter\n",
    "#Creates a random unique Test Set based on the hash of each instance's identifier.\n",
    "#The Test Set will be ${test_ratio}% of the whole dataset.\n",
    "#DrawBack: Dataset needs a unique identifier column to work.\n",
    "#If no unique identifier exists, an index can be used.\n",
    "#An alternative to using the row index is to build a unique identifier joining two columns.\n",
    "def test_set_check(identifier, test_ratio):\n",
    "    #Checks if the hash of the identifier is < than ${test_ratio}%\n",
    "    return crc32(np.int64(identifier)) & 0xffffffff < test_ratio * 2**32\n",
    "\n",
    "\n",
    "def hash_random_test_splitter(data, test_ratio, id_column):\n",
    "    ids = data[id_column]\n",
    "    #Creates a two column array (id, test_set_check: True/False)\n",
    "    in_test_set = ids.apply(lambda id_: test_set_check(id_, test_ratio))\n",
    "    \n",
    "    #Values with true will be for the test set and values with false for the trainning set.\n",
    "    return data.loc[~in_test_set], data.loc[in_test_set]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STATING WHICH VARIABLES TO GET PREDICT AND TARGET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'OSA_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-fba60f86faf9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Get all the columns from the dataframe.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOSA_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Filter the columns to remove ones we don't want.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'OSA_df' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "### Picking predictor columns\n",
    "\n",
    "# Get all the columns from the dataframe.\n",
    "columns = OSA_df.columns.tolist()\n",
    "\n",
    "# Filter the columns to remove ones we don't want.\n",
    "columns = [c for c in columns if c not in [\"IAH\",\"Gender\", \"Patient\"]]\n",
    "\n",
    "# Store the variable we'll be predicting on.\n",
    "target = \"IAH\"\n",
    "\n",
    "print('Predictors: ',columns)\n",
    "print('')\n",
    "print('Target: ',target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# splitting process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#random training splitting 80/20\n",
    "train_df, test_df = simple_random_test_splitter(OSA_df, 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting with seed\n",
    "train_df, test_df = seed_random_test_splitter(OSA_df, 0.2, 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splittinh with hash\n",
    "OSA_with_index_df = OSA_df.reset_index()\n",
    "train_df, test_df = hash_random_test_splitter(OSA_with_index_df, 0.2, \"index\")\n",
    "\n",
    "#WE CREATE A HASH UNIQUE VALUE WITH AN INVENTED FORMULA USING WEIGHT AND HEIGHT\n",
    "OSA_with_id = OSA_df\n",
    "OSA_with_id[\"id\"] = abs(OSA_df[\"Weight\"] * 1000 + OSA_df[\"Height\"])\n",
    "\n",
    "train_df, test_df = hash_random_test_splitter(OSA_with_id, 0.2, \"id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IAH</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Height</th>\n",
       "      <th>Age</th>\n",
       "      <th>Cervical</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>29.6</td>\n",
       "      <td>119</td>\n",
       "      <td>174</td>\n",
       "      <td>56</td>\n",
       "      <td>48.0</td>\n",
       "      <td>119174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.0</td>\n",
       "      <td>80</td>\n",
       "      <td>173</td>\n",
       "      <td>32</td>\n",
       "      <td>40.0</td>\n",
       "      <td>80173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>109</td>\n",
       "      <td>190</td>\n",
       "      <td>32</td>\n",
       "      <td>42.0</td>\n",
       "      <td>109190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>34.0</td>\n",
       "      <td>86</td>\n",
       "      <td>169</td>\n",
       "      <td>39</td>\n",
       "      <td>42.0</td>\n",
       "      <td>86169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>60.0</td>\n",
       "      <td>145</td>\n",
       "      <td>172</td>\n",
       "      <td>47</td>\n",
       "      <td>44.0</td>\n",
       "      <td>145172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>630</th>\n",
       "      <td>4.7</td>\n",
       "      <td>73</td>\n",
       "      <td>169</td>\n",
       "      <td>49</td>\n",
       "      <td>34.0</td>\n",
       "      <td>73169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>632</th>\n",
       "      <td>36.3</td>\n",
       "      <td>82</td>\n",
       "      <td>165</td>\n",
       "      <td>64</td>\n",
       "      <td>39.0</td>\n",
       "      <td>82165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>633</th>\n",
       "      <td>9.2</td>\n",
       "      <td>105</td>\n",
       "      <td>180</td>\n",
       "      <td>35</td>\n",
       "      <td>45.0</td>\n",
       "      <td>105180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>634</th>\n",
       "      <td>52.2</td>\n",
       "      <td>90</td>\n",
       "      <td>180</td>\n",
       "      <td>50</td>\n",
       "      <td>42.0</td>\n",
       "      <td>90180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>636</th>\n",
       "      <td>31.9</td>\n",
       "      <td>70</td>\n",
       "      <td>163</td>\n",
       "      <td>60</td>\n",
       "      <td>35.0</td>\n",
       "      <td>70163</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>512 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      IAH  Weight  Height  Age  Cervical      id\n",
       "0    29.6     119     174   56      48.0  119174\n",
       "2     9.0      80     173   32      40.0   80173\n",
       "3     2.0     109     190   32      42.0  109190\n",
       "4    34.0      86     169   39      42.0   86169\n",
       "5    60.0     145     172   47      44.0  145172\n",
       "..    ...     ...     ...  ...       ...     ...\n",
       "630   4.7      73     169   49      34.0   73169\n",
       "632  36.3      82     165   64      39.0   82165\n",
       "633   9.2     105     180   35      45.0  105180\n",
       "634  52.2      90     180   50      42.0   90180\n",
       "636  31.9      70     163   60      35.0   70163\n",
       "\n",
       "[512 rows x 6 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IAH</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Height</th>\n",
       "      <th>Age</th>\n",
       "      <th>Cervical</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19.7</td>\n",
       "      <td>78</td>\n",
       "      <td>168</td>\n",
       "      <td>39</td>\n",
       "      <td>42.0</td>\n",
       "      <td>78168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>7.0</td>\n",
       "      <td>50</td>\n",
       "      <td>158</td>\n",
       "      <td>50</td>\n",
       "      <td>35.0</td>\n",
       "      <td>50158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5.0</td>\n",
       "      <td>55</td>\n",
       "      <td>156</td>\n",
       "      <td>62</td>\n",
       "      <td>38.0</td>\n",
       "      <td>55156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15.0</td>\n",
       "      <td>65</td>\n",
       "      <td>152</td>\n",
       "      <td>59</td>\n",
       "      <td>36.0</td>\n",
       "      <td>65152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>4.0</td>\n",
       "      <td>60</td>\n",
       "      <td>162</td>\n",
       "      <td>53</td>\n",
       "      <td>33.0</td>\n",
       "      <td>60162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>618</th>\n",
       "      <td>15.0</td>\n",
       "      <td>85</td>\n",
       "      <td>162</td>\n",
       "      <td>60</td>\n",
       "      <td>41.0</td>\n",
       "      <td>85162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>623</th>\n",
       "      <td>25.0</td>\n",
       "      <td>98</td>\n",
       "      <td>169</td>\n",
       "      <td>38</td>\n",
       "      <td>44.0</td>\n",
       "      <td>98169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>624</th>\n",
       "      <td>41.5</td>\n",
       "      <td>113</td>\n",
       "      <td>180</td>\n",
       "      <td>44</td>\n",
       "      <td>44.0</td>\n",
       "      <td>113180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>631</th>\n",
       "      <td>27.9</td>\n",
       "      <td>75</td>\n",
       "      <td>171</td>\n",
       "      <td>83</td>\n",
       "      <td>40.0</td>\n",
       "      <td>75171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>635</th>\n",
       "      <td>5.4</td>\n",
       "      <td>66</td>\n",
       "      <td>164</td>\n",
       "      <td>57</td>\n",
       "      <td>35.0</td>\n",
       "      <td>66164</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>125 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      IAH  Weight  Height  Age  Cervical      id\n",
       "1    19.7      78     168   39      42.0   78168\n",
       "9     7.0      50     158   50      35.0   50158\n",
       "10    5.0      55     156   62      38.0   55156\n",
       "14   15.0      65     152   59      36.0   65152\n",
       "18    4.0      60     162   53      33.0   60162\n",
       "..    ...     ...     ...  ...       ...     ...\n",
       "618  15.0      85     162   60      41.0   85162\n",
       "623  25.0      98     169   38      44.0   98169\n",
       "624  41.5     113     180   44      44.0  113180\n",
       "631  27.9      75     171   83      40.0   75171\n",
       "635   5.4      66     164   57      35.0   66164\n",
       "\n",
       "[125 rows x 6 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fitting models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting a linear regression\n",
    "\n",
    "# Import the linear models.\n",
    "from sklearn import linear_model\n",
    "\n",
    "# Initialize the model class.\n",
    "\n",
    "model= linear_model.LinearRegression()\n",
    "\n",
    "#model= linear_model.Ridge(alpha = 0.5)\n",
    "# Fit the model to the training data.\n",
    "Trained_model=model.fit(train_df[columns], train_df[target])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mariabrullmartinez/anaconda3/envs/uni/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Unknown label type: 'continuous'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-083de80f4a7c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mTrained_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/uni/lib/python3.7/site-packages/sklearn/linear_model/logistic.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1531\u001b[0m         X, y = check_X_y(X, y, accept_sparse='csr', dtype=_dtype, order=\"C\",\n\u001b[1;32m   1532\u001b[0m                          accept_large_sparse=solver != 'liblinear')\n\u001b[0;32m-> 1533\u001b[0;31m         \u001b[0mcheck_classification_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1534\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1535\u001b[0m         \u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/uni/lib/python3.7/site-packages/sklearn/utils/multiclass.py\u001b[0m in \u001b[0;36mcheck_classification_targets\u001b[0;34m(y)\u001b[0m\n\u001b[1;32m    167\u001b[0m     if y_type not in ['binary', 'multiclass', 'multiclass-multioutput',\n\u001b[1;32m    168\u001b[0m                       'multilabel-indicator', 'multilabel-sequences']:\n\u001b[0;32m--> 169\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Unknown label type: %r\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Unknown label type: 'continuous'"
     ]
    }
   ],
   "source": [
    "#logistic regression \n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model=LogisticRegression()\n",
    "\n",
    "Trained_model = model.fit(train_df[columns], train_df[target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decision tree regressor\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "model = DecisionTreeRegressor(max_depth=3)\n",
    "Trained_model = model.fit(train_df[columns], train_df[target])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unknown label type: 'continuous'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-20d420515042>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDecisionTreeClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_depth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mClassified_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/uni/lib/python3.7/site-packages/sklearn/tree/tree.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    814\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    815\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 816\u001b[0;31m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[1;32m    817\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/uni/lib/python3.7/site-packages/sklearn/tree/tree.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_classification\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m             \u001b[0mcheck_classification_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    155\u001b[0m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/uni/lib/python3.7/site-packages/sklearn/utils/multiclass.py\u001b[0m in \u001b[0;36mcheck_classification_targets\u001b[0;34m(y)\u001b[0m\n\u001b[1;32m    167\u001b[0m     if y_type not in ['binary', 'multiclass', 'multiclass-multioutput',\n\u001b[1;32m    168\u001b[0m                       'multilabel-indicator', 'multilabel-sequences']:\n\u001b[0;32m--> 169\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Unknown label type: %r\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Unknown label type: 'continuous'"
     ]
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "\n",
    "model = tree.DecisionTreeClassifier(max_depth=2)\n",
    "Classified_model = model.fit(train_df[columns], train_df[target])\n",
    "\n",
    "\n",
    "model.plot_tree(model.fit(train_df[columns], train_df[target])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFittedError",
     "evalue": "This DecisionTreeClassifier instance is not fitted yet. Call 'fit' with appropriate arguments before using this method.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-3c64066041bc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m export_graphviz(model, out_file= '/Users/mariabrullmartinez/RSeminar-master/OSA_CaseStudy/DATA/osa_tree.dot', \n\u001b[0;32m----> 4\u001b[0;31m                 rounded= True, filled = True)\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/uni/lib/python3.7/site-packages/sklearn/tree/export.py\u001b[0m in \u001b[0;36mexport_graphviz\u001b[0;34m(decision_tree, out_file, max_depth, feature_names, class_names, label, filled, leaves_parallel, impurity, node_ids, proportion, rotate, rounded, special_characters, precision)\u001b[0m\n\u001b[1;32m    755\u001b[0m     \"\"\"\n\u001b[1;32m    756\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 757\u001b[0;31m     \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecision_tree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'tree_'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    758\u001b[0m     \u001b[0mown_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    759\u001b[0m     \u001b[0mreturn_string\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/uni/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_is_fitted\u001b[0;34m(estimator, attributes, msg, all_or_any)\u001b[0m\n\u001b[1;32m    912\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    913\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mall_or_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mattr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mattributes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 914\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mNotFittedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'name'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    915\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotFittedError\u001b[0m: This DecisionTreeClassifier instance is not fitted yet. Call 'fit' with appropriate arguments before using this method."
     ]
    }
   ],
   "source": [
    "from sklearn.tree import export_graphviz\n",
    "\n",
    "export_graphviz(model, out_file= '/Users/mariabrullmartinez/RSeminar-master/OSA_CaseStudy/DATA/osa_tree.dot', \n",
    "                rounded= True, filled = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "$ dot -Tpng osa_tree.dot -o osa_tree.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random Forest model \n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor \n",
    "\n",
    "model = RandomForestRegressor()\n",
    "Trained_model = model.fit(train_df[columns], train_df[target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#svm regression\n",
    "\n",
    "from sklearn.svm import LinearSVR\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "model= LinearSVR(epsilon=1.5)\n",
    "Trained_model=model.fit(train_df[columns], train_df[target])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVR\n",
    "\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "svm_poly_reg = SVR( kernel='poly',degree='2', C='100', epsilon='0.1')\n",
    "svm_poly_reg.fit (train_df[columns], train_df[target])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# calculating mse, r^2 and std "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions: [17.814092338104807, 5.757227306434348, 14.205059982293825, 14.506349600259, 5.336653594506689, 33.67445388465686, 17.571311836002337, 17.248001471855602, 15.997234428762567, 37.71067857128476, 11.474877511948982, 23.98340713451018, 8.9024152986566, 19.43310389676129, 13.766316935537873, 15.35080860947739, 29.75028512030631, 21.43659765211916, 13.846701649394447, 13.922337741204068, 20.031430161170498, 13.484674192552376, 11.272015418800876, 33.18873143847283, 24.84418058791369, 18.341059999850707, 8.89941237069575, 15.215128910518636, 16.285740614539137, 29.530012791077425, 14.348718727851448, 45.05946667513961, 22.1016477994148, 17.1459372566057, 16.810058181190804, 12.698899550365752, 10.84835761810124, 20.357970949869156, 2.6931622813847014, 22.17600933003895, 10.173027797931276, 14.31455886631553, 27.41834225259234, 43.32073232312987, 22.32553230145134, 17.999247125848292, 22.09068211864647, 16.461999333077898, 25.333348179570088, 28.2048435600166, 12.912779569704199, 33.232371216791925, 22.01504602683685, 17.82788217754416, 20.710830665451034, 25.25094713309126, 10.786857162356078, 34.37002720305559, 9.401977345100583, 10.267981261886874, 4.971180992192252, 25.04764282243164, 37.761663633730755, 7.588702693176884, 20.458042162529715, 14.980132391933836, 0.9668062832749378, 12.949573232542953, 7.496504848678896, 36.934120397659605, 14.855645870334492, 21.545743703274255, 23.133351019852427, 16.51926750885726, 4.817315664613812, 13.49120813250974, 27.144820186272646, 22.389167389852773, 4.565972268334008, 8.869469529050356, 36.390578361627625, 24.544391840132803, 24.544359406622938, 7.195901238607725, 9.658458301997506, 34.957618801408316, 41.721180954278545, 31.345603329548645, 7.814604561355004, 5.8742989711740385, 17.458967947878115, 10.68126193510966, 10.826089563416446, 21.94329026176961, 15.915750404889586, 20.067817558128354, 12.593848700946403, 26.626208921617405, 31.069029607966833, 19.68548613380171, 14.77478283326284, 2.436291352398282, 12.79775315297588, 32.05115221525635, 12.296600851702692, 20.32860843768146, 9.96139512592692, 16.543990595555073, 20.4217963956388, 14.882694980576105, 22.431419012665387, 7.458810457025706, 39.01127353602916, 16.59686768786711, 1.4283372449175857, 23.92355388472925, 13.497315994674047, 18.828154307749813, 7.95040975066221, 25.77581259569076, 24.29200960309238, 25.360166275099864, 27.862799671302348, 22.939563765198862, 9.988671732759613]\n",
      "labels: [29.6, 9.0, 2.0, 34.0, 60.0, 22.0, 11.0, 3.7, 26.0, 22.0, 10.0, 4.3, 20.0, 56.0, 53.6, 2.1, 27.0, 32.0, 11.0, 24.6, 14.8, 17.0, 31.5, 43.0, 12.8, 37.3, 3.0, 34.0, 46.3, 27.0, 0.0, 28.3, 3.0, 69.0, 32.0, 31.0, 36.0, 2.0, 5.0, 24.0, 13.7, 40.0, 10.0, 0.0, 4.2, 30.0, 36.3, 5.8, 7.9, 3.8, 42.3, 15.5, 35.0, 3.3, 22.0, 2.5, 3.0, 11.8, 43.36, 6.4, 1.2, 6.3, 30.0, 5.4, 3.0, 11.0, 17.3, 8.8, 5.0, 2.2, 6.3, 10.9, 6.5, 14.5, 9.6, 23.7, 87.0, 8.4, 23.3, 3.4, 5.0, 24.3, 60.0, 7.4, 70.0, 5.4, 10.9, 2.1, 44.7, 1.4, 3.7, 11.3, 4.8, 52.3, 20.0, 30.0, 25.8, 3.4, 35.0, 3.0, 10.6, 8.4, 0.0, 28.0, 7.2, 29.0, 19.4, 8.4, 24.7, 32.3, 16.4, 2.4, 0.0, 35.7, 7.3, 15.4, 8.0, 20.8, 38.3, 0.0, 4.0, 4.0, 0.7, 1.4, 29.0, 14.3, 13.1, 3.6, 5.9, 10.3, 15.6, 17.0, 19.8, 59.6, 6.0, 6.0, 2.3, 20.0, 49.0, 30.0, 20.0, 26.0, 15.0, 45.0, 13.0, 6.0, 6.9, 44.6, 30.0, 2.1, 26.4, 4.8, 22.3, 8.1, 19.0, 33.3, 46.0, 37.0, 10.8, 7.1, 4.8, 27.6, 19.0, 15.2, 50.9, 9.2, 58.5, 35.0, 9.5, 51.6, 1.5, 15.0, 1.3, 37.9, 14.0, 8.9, 38.0, 27.3, 14.1, 15.0, 3.0, 6.1, 11.6, 48.7, 40.8, 20.0, 21.7, 4.2, 24.8, 3.0, 3.0, 12.6, 8.0, 11.9, 13.5, 5.5, 10.8, 2.0, 5.0, 31.0, 20.7, 3.4, 30.0, 3.5, 2.0, 1.0, 8.0, 4.2, 84.8, 21.9, 3.5, 8.9, 57.0, 13.0, 10.0, 40.9, 3.6, 1.9, 4.3, 35.0, 2.5, 7.3, 9.0, 9.6, 3.2, 21.4, 2.6, 40.0, 8.1, 51.0, 6.6, 33.0, 4.1, 5.9, 108.4, 24.0, 34.0, 25.8, 3.0, 11.0, 58.4, 25.0, 9.0, 2.0, 3.4, 33.1, 36.8, 61.5, 5.1, 29.1, 23.6, 11.0, 19.0, 15.0, 65.0, 4.0, 65.0, 0.0, 61.0, 6.0, 34.0, 43.0, 13.6, 5.3, 11.4, 43.0, 0.0, 13.5, 38.0, 0.0, 27.0, 28.9, 0.8, 15.9, 27.8, 2.1, 12.6, 11.0, 0.0, 21.0, 11.8, 51.0, 74.0, 16.9, 15.2, 25.0, 6.9, 8.4, 71.3, 0.0, 84.4, 18.6, 6.0, 11.7, 24.0, 12.5, 13.2, 6.4, 38.7, 29.7, 53.0, 10.1, 51.9, 7.5, 31.4, 18.6, 0.0, 13.8, 21.7, 32.0, 13.5, 1.0, 17.8, 53.0, 2.5, 17.0, 11.0, 7.9, 0.0, 20.0, 17.4, 13.0, 12.0, 34.0, 19.3, 34.3, 19.0, 19.4, 28.2, 0.0, 33.0, 20.2, 48.1, 11.7, 37.6, 5.7, 24.0, 10.7, 20.0, 19.0, 17.0, 10.0, 15.8, 13.3, 0.0, 29.3, 4.1, 35.9, 4.4, 10.6, 4.6, 22.5, 15.0, 29.0, 3.7, 0.0, 7.6, 9.0, 10.7, 30.0, 9.0, 16.3, 10.0, 7.5, 13.3, 10.2, 64.0, 39.6, 3.9, 54.0, 29.9, 35.3, 40.0, 42.2, 0.0, 11.5, 55.0, 22.6, 7.0, 13.7, 4.2, 0.0, 4.4, 9.5, 13.2, 32.5, 54.5, 64.5, 19.6, 0.7, 0.0, 1.8, 8.0, 15.6, 19.4, 2.6, 35.7, 11.2, 24.9, 44.7, 19.7, 4.6, 1.7, 15.4, 25.0, 45.0, 6.8, 74.3, 27.6, 14.4, 31.8, 63.1, 1.4, 9.9, 6.9, 13.3, 36.0, 3.3, 11.7, 27.0, 31.0, 0.7, 30.0, 30.0, 3.8, 45.3, 56.5, 17.2, 11.1, 14.3, 57.1, 23.0, 20.7, 34.0, 34.3, 22.0, 0.0, 6.8, 30.0, 2.8, 0.0, 0.0, 7.5, 15.0, 11.7, 16.1, 33.9, 31.3, 0.0, 10.0, 10.0, 27.0, 9.2, 11.8, 37.8, 10.0, 35.2, 40.0, 27.3, 16.0, 42.3, 1.8, 24.7, 11.7, 31.1, 0.0, 102.0, 10.4, 2.8, 50.0, 16.6, 19.4, 13.8, 16.2, 2.6, 11.0, 7.8, 19.7, 33.1, 30.0, 17.8, 0.0, 84.3, 9.0, 0.4, 45.7, 20.3, 2.1, 21.3, 6.1, 0.0, 22.0, 10.2, 8.2, 16.7, 27.9, 0.0, 8.8, 52.6, 64.3, 17.2, 4.8, 2.7, 57.0, 108.6, 4.6, 33.0, 4.7, 36.3, 9.2, 52.2, 31.9]\n"
     ]
    }
   ],
   "source": [
    "### Predicting Error\n",
    "\n",
    "# Import the scikit-learn function to compute error.\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Generate our predictions for the test set.\n",
    "predictions = model.predict(test_df[columns])\n",
    "\n",
    "print ('predictions:',  list(predictions))\n",
    "print ('labels:', list(train_df[target]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared Error:  15.97114472032819\n"
     ]
    }
   ],
   "source": [
    "# Compute error between our test predictions and the actual values.\n",
    "MSE=mean_squared_error(predictions, test_df[target])\n",
    "MSE = np.sqrt(MSE)\n",
    "print('Mean squared Error: ', MSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r^2: 0.20\n"
     ]
    }
   ],
   "source": [
    "# Explained variance score: \n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "print('r^2: %.2f' % r2_score(test_df[target], predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variance score: 0.22\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import explained_variance_score\n",
    "\n",
    "print('Variance score: %.2f' % explained_variance_score(test_df[target], predictions, multioutput='uniform_average'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "continuous is not supported",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-31b74dddadec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mprecision_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecall_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;34m'precision score: %.2f'\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0mprecision_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;34m'precision score: %.2f'\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0mrecall_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/uni/lib/python3.7/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36mprecision_score\u001b[0;34m(y_true, y_pred, labels, pos_label, average, sample_weight)\u001b[0m\n\u001b[1;32m   1567\u001b[0m                                                  \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maverage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1568\u001b[0m                                                  \u001b[0mwarn_for\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'precision'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1569\u001b[0;31m                                                  sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m   1570\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1571\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/uni/lib/python3.7/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36mprecision_recall_fscore_support\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight)\u001b[0m\n\u001b[1;32m   1413\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"beta should be >0 in the F-beta score\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1414\u001b[0m     labels = _check_set_wise_labels(y_true, y_pred, average, labels,\n\u001b[0;32m-> 1415\u001b[0;31m                                     pos_label)\n\u001b[0m\u001b[1;32m   1416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m     \u001b[0;31m# Calculate tp_sum, pred_sum, true_sum ###\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/uni/lib/python3.7/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36m_check_set_wise_labels\u001b[0;34m(y_true, y_pred, average, labels, pos_label)\u001b[0m\n\u001b[1;32m   1237\u001b[0m                          str(average_options))\n\u001b[1;32m   1238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1239\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1240\u001b[0m     \u001b[0mpresent_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munique_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0maverage\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'binary'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/uni/lib/python3.7/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;31m# No metrics support \"multiclass-multioutput\" format\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0my_type\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"binary\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"multiclass\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"multilabel-indicator\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"{0} is not supported\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"binary\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"multiclass\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: continuous is not supported"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "print( 'precision score: %.2f' %precision_score(test_df[target], predictions))\n",
    "print( 'precision score: %.2f' %recall_score(test_df[target], predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mariabrullmartinez/anaconda3/envs/uni/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/mariabrullmartinez/anaconda3/envs/uni/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/mariabrullmartinez/anaconda3/envs/uni/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/mariabrullmartinez/anaconda3/envs/uni/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/mariabrullmartinez/anaconda3/envs/uni/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/mariabrullmartinez/anaconda3/envs/uni/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/mariabrullmartinez/anaconda3/envs/uni/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/mariabrullmartinez/anaconda3/envs/uni/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/mariabrullmartinez/anaconda3/envs/uni/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/mariabrullmartinez/anaconda3/envs/uni/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "#K FOLD CROSS VALIDATION FEATURE \n",
    "#randomly splits the training set into k distinct subset called folds, \n",
    "# and trains and evaluates the decision tree k time, picking a different fold \n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(model,train_df[columns], train_df[target],\n",
    "                        scoring='neg_mean_squared_error', cv=10)\n",
    "rmse_scores = np.sqrt(-scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [18.90395859 18.73151585 14.12571635 15.95178631 25.15652605 21.90792571\n",
      " 12.5000287  20.52386463 17.23956073 26.4901656 ]\n",
      "Mean: 19.153104851177613\n",
      "Standard Deviation: 4.278194792829798\n"
     ]
    }
   ],
   "source": [
    "def display_scores (scores):\n",
    "    print ('Scores:', scores)\n",
    "    print ('Mean:', scores.mean())\n",
    "    print ('Standard Deviation:' , scores.std())\n",
    "    \n",
    "display_scores(rmse_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(model,train_df[columns], train_df[target],\n",
    "                        scoring='accuracy', cv=10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[target] = train_df[target].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#confusion matrix\n",
    "\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "predictions = cross_val_predict(model,train_df[columns], train_df[target], cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix[train_df[target], predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ROC curve\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "thresholds =0.1\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(train_df[target],rmse_scores)\n",
    "\n",
    "def plot_roc_curve (fpr, tpr ):\n",
    "    plt.plot(fpr, tpr, linewidth=2, label=label)\n",
    "    plt.plot([0,1], [0,1], 'k--')\n",
    "    \n",
    "plot_roc_curve(fpr, tpr)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM CLASSIFICATION "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mariabrullmartinez/anaconda3/envs/uni/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "model = svm.SVR()\n",
    "Trained_model = model.fit(train_df[columns], train_df[target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Random sampling method. Similar to simple_random_test_splitter approach.\n",
    "#More than one dataset can be included and all of them will be splitted on the same indices.\n",
    "train_set, test_set = train_test_split(OSA_df, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stratified sampling method.\n",
    "#The population is divided homogeneous subgroups (strata). \n",
    "#The trainning and testing sets have to have the right proportion of each stratum to be representative \n",
    "#of the population.\n",
    "\n",
    "#Using the OSA dataset, given that the IAH is a very important attribute to predict \n",
    "#OSA condition we will want to ensure that the testing and trainning set are representative of the\n",
    "#various categories of OSA.\n",
    "#First we should check how the IAH is distributed:\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "OSA_df[\"IAH\"].hist(bins=50, figsize=(20,15))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We can see that most of the values lie between 0 and 40, and that values extend far on the right \n",
    "#compared to the left.\n",
    "\n",
    "#Now we will want to create a set of categories (stratum) with value ranges to gather the data. \n",
    "#It is important to have suficient number of instances in each stratum to prevent \n",
    "#biasing the importance of each stratum.\n",
    "\n",
    "#We are going to IAH in 3 categories:\n",
    "OSA_df[\"OSA_var\"] = pd.cut(OSA_df[\"IAH\"],\n",
    "                                  bins=[0., 10., 30., np.inf],\n",
    "                                  labels=[1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OSA_df[\"OSA_var\"].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finally we can do stratified sampling based on IAH:\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "#n_splits -> Nº of trainning/test samples.\n",
    "#test_size -> size of test sample (0<x<1).\n",
    "#random_state -> seed for the random generator.\n",
    "split = StratifiedShuffleSplit(n_splits=2, test_size=0.2, random_state=42)\n",
    "\n",
    "#Will go through the loop one time per n_splits.\n",
    "for train_indices, test_indices in split.split(OSA_df, OSA_df[\"OSA\"]):\n",
    "    print(\"TRAIN:\", train_indices, \"TEST:\", test_indices)\n",
    "    strat_train_set = OSA_df.loc[train_indices]\n",
    "    strat_test_set = OSA_df.loc[test_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
