{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"MLLB_Keras_RNN_TextGeneration.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.5"}},"cells":[{"cell_type":"markdown","metadata":{"colab_type":"text","id":"dUNKDytx2E6E"},"source":["## Text Prediction/Generation with Keras using <font color= #13c113  >LSTM: *Long Short Term Memory* networks</font>\n","\n","   In this example we will work with the book: Alice’s Adventures in Wonderland by Lewis Carroll.\n","\n","  We are going to learn the dependencies between characters and the conditional probabilities of characters in sequences so that we can in turn generate wholly new and original sequences of characters.\n","    \n","![Text-Generation-With-LSTM-Recurrent-Neural-Networks-in-Python-with-Keras](https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2016/08/Text-Generation-With-LSTM-Recurrent-Neural-Networks-in-Python-with-Keras.jpg)\n","\n","\n","### Adapted from:\n","#### [Text Generation With LSTM Recurrent Neural Networks in Python with Keras](https://machinelearningmastery.com/text-generation-lstm-recurrent-neural-networks-python-keras/)\n","\n","By Jason Brownlee\n","\n","\n","<br>\n"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"FsnDWHL0sYVC"},"source":["<img src=\"https://s3.amazonaws.com/keras.io/img/keras-logo-2018-large-1200.png\" alt=\"Keras logo\" height=\"100\" width=\"250\"> \n","\n","---\n","\n","\n","# * [MSTC](http://mstc.ssr.upm.es/big-data-track) and MUIT: <font size=5 color='green'>Deep Learning</font>\n","\n","* <font size=5 color='green'>Machine Learning Lab (MLLB)</font>\n"," \n","---\n","---\n"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"d7BYb9WvopbE"},"source":["\n","\n","---\n","\n","## Start installing some libraries do some imports..."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"6UFqWyqn2E6P","colab":{}},"source":["import numpy as np\n","\n","import keras\n","\n","from keras.models import Sequential\n","from keras.layers import Dense\n","from keras.layers import Dropout\n","from keras.layers import LSTM\n","from keras.callbacks import ModelCheckpoint\n","from keras.utils import np_utils\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"odDMNWMpVwpI"},"source":["\n","\n","---\n","\n","## Down load TEXT file <font color= #2a9dad >*Alice’s Adventures in Wonderland*</font>"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"8BoeyLdlAMFk"},"source":["- ### We will first download the complete text in ASCII format (Plain Text UTF-8) \n","\n","- #### [Project Gutenberg](https://www.gutenberg.org/): gives free access to books that are no longer protected by copyright\n","\n","- ### Text has been prepared in a Google Drive link\n","\n"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"wVLz9hSvmsiC","outputId":"9a0ee6c2-e9b3-476e-9aee-0e333326c2ac","executionInfo":{"status":"ok","timestamp":1574968423623,"user_tz":-60,"elapsed":6586,"user":{"displayName":"Maria Brull","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAlf9Wj2cIkz8I0xIM_gnFXMx7wdLhFh3LmnxBb=s64","userId":"01827463003857096616"}},"colab":{"base_uri":"https://localhost:8080/","height":63}},"source":["! pip install googledrivedownloader"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: googledrivedownloader in /usr/local/lib/python3.6/dist-packages (0.4)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Db_o1gvImUm6","outputId":"747066a4-6af5-4cde-a878-fbb2d702e3ba","executionInfo":{"status":"ok","timestamp":1574968426922,"user_tz":-60,"elapsed":1012,"user":{"displayName":"Maria Brull","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAlf9Wj2cIkz8I0xIM_gnFXMx7wdLhFh3LmnxBb=s64","userId":"01827463003857096616"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["from google_drive_downloader import GoogleDriveDownloader as gdd\n","\n","gdd.download_file_from_google_drive(file_id='1wG4PUnoYVUKrsaWgyWepSacUiYNNDEvM',\n","                                    dest_path='./wonderland.txt',\n","                                    unzip=False)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Downloading 1wG4PUnoYVUKrsaWgyWepSacUiYNNDEvM into ./wonderland.txt... Done.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"jex6dqRlWsKQ"},"source":["- ### Read text for the book and convert all of the characters to lowercase to reduce the vocabulary that the network must learn"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"R2IU6TLHWky6","colab":{}},"source":["# load ascii text and covert to lowercase\n","filename = \"wonderland.txt\"\n","raw_text = open(filename).read()\n","raw_text = raw_text.lower()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"e6_VWNBKa2ku","outputId":"7a2151e0-5067-4a0f-c97d-6f837e7d9497","executionInfo":{"status":"ok","timestamp":1574968431705,"user_tz":-60,"elapsed":697,"user":{"displayName":"Maria Brull","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAlf9Wj2cIkz8I0xIM_gnFXMx7wdLhFh3LmnxBb=s64","userId":"01827463003857096616"}},"colab":{"base_uri":"https://localhost:8080/","height":238}},"source":["print(raw_text[0:200])\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["alice's adventures in wonderland\n","\n","lewis carroll\n","\n","the millennium fulcrum edition 3.0\n","\n","\n","\n","\n","chapter i. down the rabbit-hole\n","\n","alice was beginning to get very tired of sitting by her sister on the\n","bank, and\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"J7ZPLsFQXGCE"},"source":["- ### We must use a \"numerical\" representation of text characters directly,\n","- ### We will start using a simple one: $integers$\n","- ### (Some characters could have been removed to further clean up the text)"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"F-HDPTBJZuDP"},"source":["<font color=yellow  face=\"times, serif\" size=5>============================================<br>\n","How many different characters in raw_text?  store then ordered in a list</font>"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"ss0TJIsyaKYg","outputId":"86dfc160-8476-4b21-b205-37de6b4a191c","executionInfo":{"status":"ok","timestamp":1574968446452,"user_tz":-60,"elapsed":12492,"user":{"displayName":"Maria Brull","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAlf9Wj2cIkz8I0xIM_gnFXMx7wdLhFh3LmnxBb=s64","userId":"01827463003857096616"}},"colab":{"base_uri":"https://localhost:8080/","height":91}},"source":["chars = sorted(list(set(raw_text)))\n","\n","print(chars)\n","print('Number of characters: ',len(chars))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["['\\n', ' ', '!', '\"', \"'\", '(', ')', '*', ',', '-', '.', '0', '3', ':', ';', '?', '[', ']', '_', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n","Number of characters:  45\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"IojHeJjubjiy"},"source":["<font color=yellow  face=\"times, serif\" size=5>============================================<br>\n","MAP each character to an integer using a Python *dictionary*  with key(char) : value(int) </font>"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"z3LONt7Ub3zt","colab":{}},"source":["char_to_int = dict((c, i) for i, c in enumerate(chars))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"QG_-e37heJhl","outputId":"34266fe1-7d7e-4411-8081-c14b69354a76","executionInfo":{"status":"ok","timestamp":1574968460025,"user_tz":-60,"elapsed":965,"user":{"displayName":"Maria Brull","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAlf9Wj2cIkz8I0xIM_gnFXMx7wdLhFh3LmnxBb=s64","userId":"01827463003857096616"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["char_to_int['s']"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["37"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"QGakftCBeVdO"},"source":["<font color=yellow face=\"times, serif\" size=5>============================================<br>\n","INVERSE MAP: get the char from an integer using a *dictionary*  int: char </font>"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"ByLYr2_5W5rG","colab":{}},"source":["int_to_char = dict((i, c) for i, c in enumerate(chars))\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"z1LxL5F9fWZo","outputId":"770baf23-3f50-4488-d37c-a331a2825776","executionInfo":{"status":"ok","timestamp":1574968463006,"user_tz":-60,"elapsed":1071,"user":{"displayName":"Maria Brull","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAlf9Wj2cIkz8I0xIM_gnFXMx7wdLhFh3LmnxBb=s64","userId":"01827463003857096616"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["int_to_char[3]"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'\"'"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"rggkUQX7fP6j","outputId":"49f8e5fc-96b5-42e0-8f91-deccd5567f2c","executionInfo":{"status":"ok","timestamp":1574968464935,"user_tz":-60,"elapsed":1020,"user":{"displayName":"Maria Brull","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAlf9Wj2cIkz8I0xIM_gnFXMx7wdLhFh3LmnxBb=s64","userId":"01827463003857096616"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["n_chars = len(raw_text)\n","n_vocab = len(chars)\n","print(\"Total Characters: \", n_chars)\n","print(\"Total Vocab: \", n_vocab)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Total Characters:  144431\n","Total Vocab:  45\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"Bt8y8RI2t7c0"},"source":["---\n","\n","## Prediction Task:\n","\n","\n","- ### <font color=red> Number of steps</font>: We will split the book text up into subsequences with a <font color=red>fixed length of 100 characters, an arbitrary length</font>. \n","\n","- ### To train the network we slide a windows of seq_length = 100 characters along the whole book\n","\n"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"38qvEI_bhSaq"},"source":["<font color=yellow  face=\"times, serif\" size=5>============================================<br>\n","**Slide a window extracting a sequence of seq_length = 100 characters along the book and store it in dataX : the input to the network</font>"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"O25hAvcYhfii","colab":{}},"source":["seq_length = 100\n","\n","dataX=[]\n","\n","for i in range(0, n_chars - seq_length, 1):\n","  seq_in = raw_text[i:i+seq_length]\n","  dataX.append(seq_in)\n","\n","#dataX"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"HeTJAgJzijQQ","outputId":"26d732a0-ec44-43f8-c40a-ccb7014c25f6","executionInfo":{"status":"ok","timestamp":1574968475934,"user_tz":-60,"elapsed":623,"user":{"displayName":"Maria Brull","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAlf9Wj2cIkz8I0xIM_gnFXMx7wdLhFh3LmnxBb=s64","userId":"01827463003857096616"}},"colab":{"base_uri":"https://localhost:8080/","height":221}},"source":["print('dataX length: ',len(dataX))\n","print('dataX first training example: \\n',dataX[0])"],"execution_count":0,"outputs":[{"output_type":"stream","text":["dataX length:  144331\n","dataX first training example: \n"," alice's adventures in wonderland\n","\n","lewis carroll\n","\n","the millennium fulcrum edition 3.0\n","\n","\n","\n","\n","chapter i. d\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"fpanFsYCjFWv"},"source":["<font color=yellow  face=\"times, serif\" size=5>============================================<br>\n","dataX MUST be numeric!!! make changes using our $char\\_to\\_int$ dictionary</font>"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"KMlzbpf8jZcf","colab":{}},"source":["seq_length = 100\n","\n","dataX=[]\n","\n","for i in range(0, n_chars - seq_length, 1):\n","  seq_in = raw_text[i:i+seq_length]\n","  dataX.append([char_to_int[char] for char in seq_in])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"GzXntZ6KkgTP","outputId":"63cf3a9c-6865-4f7a-964e-103500f6fe13","executionInfo":{"status":"ok","timestamp":1574968487286,"user_tz":-60,"elapsed":1122,"user":{"displayName":"Maria Brull","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAlf9Wj2cIkz8I0xIM_gnFXMx7wdLhFh3LmnxBb=s64","userId":"01827463003857096616"}},"colab":{"base_uri":"https://localhost:8080/","height":108}},"source":["print('dataX length: ',len(dataX))\n","print('dataX first training example: \\n',dataX[0])"],"execution_count":0,"outputs":[{"output_type":"stream","text":["dataX length:  144331\n","dataX first training example: \n"," [19, 30, 27, 21, 23, 4, 37, 1, 19, 22, 40, 23, 32, 38, 39, 36, 23, 37, 1, 27, 32, 1, 41, 33, 32, 22, 23, 36, 30, 19, 32, 22, 0, 0, 30, 23, 41, 27, 37, 1, 21, 19, 36, 36, 33, 30, 30, 0, 0, 38, 26, 23, 1, 31, 27, 30, 30, 23, 32, 32, 27, 39, 31, 1, 24, 39, 30, 21, 36, 39, 31, 1, 23, 22, 27, 38, 27, 33, 32, 1, 12, 10, 11, 0, 0, 0, 0, 0, 21, 26, 19, 34, 38, 23, 36, 1, 27, 10, 1, 22]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"T0_kYn0DlCUM"},"source":["<font color=yellow  face=\"times, serif\" size=5>============================================<br>\n","Now we have to create the output for each 100 characters windows: </font>\n","  - the OUTPUT will be the next character, that is: we will train to predict the next character after \"seeing\" 100 previous characters. </font>\n","  \n","###So add to the for loop some code to store the \"next character\" for each window in dataY  :  again this MUST be numeric!!! so use our $char\\_to\\_int$ dictionary</font>"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"ypvND-9uvG4g","colab":{}},"source":["\n","seq_length = 100\n","\n","dataX = []\n","dataY = []\n","for i in range(0, n_chars - seq_length, 1):\n","  \n","\tseq_in = raw_text[i:i + seq_length]\n","\tseq_out = raw_text[i + seq_length]\n","\tdataX.append([char_to_int[char] for char in seq_in])\n","\tdataY.append(char_to_int[seq_out])\n","\n","#dataY"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"KqguLk9umLdU","outputId":"78b55607-0c7f-4138-aecd-1156b061b366","executionInfo":{"status":"ok","timestamp":1574968535048,"user_tz":-60,"elapsed":2502,"user":{"displayName":"Maria Brull","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAlf9Wj2cIkz8I0xIM_gnFXMx7wdLhFh3LmnxBb=s64","userId":"01827463003857096616"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["import numpy as np\n","\n","n_patterns = len(dataX)\n","\n","print(\"Total Patterns: \", n_patterns)\n","print(\"Pattern shape: \",np.array(dataX).shape)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Total Patterns:  144331\n","Pattern shape:  (144331, 100)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"gTPm6IwV0D7S"},"source":["- ### Let's see two examples:"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"dNI1LWe8xOrI","outputId":"7e251929-ec48-4e34-c90e-b8dcd739eed4","executionInfo":{"status":"ok","timestamp":1574968538591,"user_tz":-60,"elapsed":872,"user":{"displayName":"Maria Brull","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAlf9Wj2cIkz8I0xIM_gnFXMx7wdLhFh3LmnxBb=s64","userId":"01827463003857096616"}},"colab":{"base_uri":"https://localhost:8080/","height":306}},"source":["print(\"------Window input dataX -------------------------------------\")\n","print(\"\\\"\", ''.join([int_to_char[value] for value in dataX[201]]), \"\\\"\")\n","print(\"\\n -----Character to predict dataY:\")\n","print(\"\\\"\", int_to_char[dataY[201]])\n","print(\"\\n\")\n","print(\"------Window input dataX -------------------------------------\")\n","print(\"\\\"\", ''.join([int_to_char[value] for value in dataX[202]]), \"\\\"\")\n","print(\"\\n -----Character to predict dataY:\")\n","print(\"\\\"\", int_to_char[dataY[202]])\n","print(\"\\n\")\n","print(\"\\\"\", ''.join([int_to_char[value] for value in dataY[203:216]]), \"\\\"\")"],"execution_count":0,"outputs":[{"output_type":"stream","text":["------Window input dataX -------------------------------------\n","\" of having nothing to do: once or twice she had peeped into the\n","book her sister was reading, but it h \"\n","\n"," -----Character to predict dataY:\n","\" a\n","\n","\n","------Window input dataX -------------------------------------\n","\" f having nothing to do: once or twice she had peeped into the\n","book her sister was reading, but it ha \"\n","\n"," -----Character to predict dataY:\n","\" d\n","\n","\n","\"  no pictures  \"\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"uDwrt7he0aIi"},"source":["\n","\n","---\n","\n","## We must now prepare our training data to be suitable for use with LSTM in Keras.\n","\n","- ### First we must transform the list of input sequences into the form <font color= #3498db>  [no. samples or batches, time steps, features]</font> expected by an LSTM network. <font color=red> NOTE that our number of features is 1</font>\n","\n","- ### Next we need to rescale the integers to the range 0-to-1 to make the patterns easier to learn by the LSTM network that uses the sigmoid activation function by default.\n","\n","- ### Finally, we need to convert the output patterns (single characters converted to integers) into a one hot encoding: to predict the probability of each of the different characters in the vocabulary"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Vnokv8nkpChv","outputId":"35f53ac2-660f-4602-a417-5373370f1958","executionInfo":{"status":"ok","timestamp":1574968543502,"user_tz":-60,"elapsed":1689,"user":{"displayName":"Maria Brull","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAlf9Wj2cIkz8I0xIM_gnFXMx7wdLhFh3LmnxBb=s64","userId":"01827463003857096616"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["print('dataX shape', np.array(dataX).shape)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["dataX shape (144331, 100)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Lk372vY7wLBw","outputId":"8a1e4326-e8bd-482a-ca61-5fb5cbcbdc3a","executionInfo":{"status":"ok","timestamp":1574968639682,"user_tz":-60,"elapsed":1672,"user":{"displayName":"Maria Brull","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAlf9Wj2cIkz8I0xIM_gnFXMx7wdLhFh3LmnxBb=s64","userId":"01827463003857096616"}},"colab":{"base_uri":"https://localhost:8080/","height":68}},"source":["from keras.utils.np_utils import to_categorical\n","\n","# reshape X to be [samples, time steps, features]\n","X = np.reshape(dataX, (n_patterns, seq_length, 1))\n","# normalize\n","X = X / float(n_vocab)\n","# one hot encode the output variable\n","y = np_utils.to_categorical(dataY)\n","y[6]"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","       0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)"]},"metadata":{"tags":[]},"execution_count":24}]},{"cell_type":"code","metadata":{"id":"Vgioo5xqAuUb","colab_type":"code","outputId":"cdbe0660-44fa-4220-a08a-d1ceeda87e2d","executionInfo":{"status":"ok","timestamp":1574968642664,"user_tz":-60,"elapsed":553,"user":{"displayName":"Maria Brull","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAlf9Wj2cIkz8I0xIM_gnFXMx7wdLhFh3LmnxBb=s64","userId":"01827463003857096616"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["dataY[6]"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["23"]},"metadata":{"tags":[]},"execution_count":25}]},{"cell_type":"markdown","metadata":{"id":"QXP-cZmgAuUd","colab_type":"text"},"source":["LO QUE ESTA HACIENDO ES SABIENDO QUE DATAY[3]=DATAY[100] ES IGUAL A 1, ENTONCES QUIERE DECIR QUE AMBOS SON EL MISMO CARACTER Y QUE SON EL CARACTER 1, DE LOS 45 CARACTERES QUE HEMOS DEFINIDO ANTES. POR LO QUE Y[3] BUSCA LO QUE HAY EN POSICION 3 DEL DATAY Y AL HACER UN ONE HOT ENCODER MUESTRA LA POSICION EN LA QUE SALE. "]},{"cell_type":"code","metadata":{"colab_type":"code","id":"YxOMpiTMpp2P","outputId":"b556b685-f19f-4831-a428-98e3b1fa567a","executionInfo":{"status":"ok","timestamp":1574968644642,"user_tz":-60,"elapsed":529,"user":{"displayName":"Maria Brull","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAlf9Wj2cIkz8I0xIM_gnFXMx7wdLhFh3LmnxBb=s64","userId":"01827463003857096616"}},"colab":{"base_uri":"https://localhost:8080/","height":85}},"source":["# or with keras\n","ykeras=keras.utils.to_categorical(dataY)\n","\n","print('OHE example numpy',y[3])\n","print('OHE example keras',ykeras[3])\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["OHE example numpy [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n","OHE example keras [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"QsAh3_py0Ywy","outputId":"ea00c25a-6ad1-4246-829f-997c8f613672","executionInfo":{"status":"ok","timestamp":1574968648091,"user_tz":-60,"elapsed":1444,"user":{"displayName":"Maria Brull","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAlf9Wj2cIkz8I0xIM_gnFXMx7wdLhFh3LmnxBb=s64","userId":"01827463003857096616"}},"colab":{"base_uri":"https://localhost:8080/","height":187}},"source":["X[200,0:10]*n_vocab"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[ 1.],\n","       [33.],\n","       [24.],\n","       [ 1.],\n","       [26.],\n","       [19.],\n","       [40.],\n","       [27.],\n","       [32.],\n","       [25.]])"]},"metadata":{"tags":[]},"execution_count":27}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"muyhcmH_qUfR"},"source":["## NOTE that to go now -after normalization- from int to chat we must multiply by n_vocab and round to integer "]},{"cell_type":"code","metadata":{"colab_type":"code","id":"vddjIgIp1_MM","outputId":"0b20153c-3d88-4cfd-8f07-3a246ba30d9b","executionInfo":{"status":"ok","timestamp":1574968649168,"user_tz":-60,"elapsed":424,"user":{"displayName":"Maria Brull","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAlf9Wj2cIkz8I0xIM_gnFXMx7wdLhFh3LmnxBb=s64","userId":"01827463003857096616"}},"colab":{"base_uri":"https://localhost:8080/","height":85}},"source":["print(\"\\\"\", ''.join([int_to_char[int(value+0.5)] for value in X[200,:]*n_vocab]), \"\\\"\")\n","print(\"\\\"\", ''.join([int_to_char[int(value)] for value in dataX[200]]), \"\\\"\")"],"execution_count":0,"outputs":[{"output_type":"stream","text":["\"  of having nothing to do: once or twice she had peeped into the\n","book her sister was reading, but it  \"\n","\"  of having nothing to do: once or twice she had peeped into the\n","book her sister was reading, but it  \"\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"F-4PJkMKL6qs"},"source":["---\n","## We can now define and compile our LSTM model:\n","- ### Here we define a single hidden LSTM layer with 256 memory units.\n","- ### The network uses dropout with a probability of 20 at the output of LSTM. <font color=red> you can also use recurrent dropout</font> SEE: [Keras layers recurrent](https://keras.io/layers/recurrent/)\n","- ### The output layer is a Dense layer using the softmax activation function to output a probability prediction for each of the possible characters between 0 and 1.\n","\n"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"fs5ggo7a88ZK","outputId":"06390cbc-012c-428f-dff4-7cce812a7da1","executionInfo":{"status":"ok","timestamp":1574968654838,"user_tz":-60,"elapsed":588,"user":{"displayName":"Maria Brull","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAlf9Wj2cIkz8I0xIM_gnFXMx7wdLhFh3LmnxBb=s64","userId":"01827463003857096616"}},"colab":{"base_uri":"https://localhost:8080/","height":102}},"source":["print('X shape: ', X.shape)\n","print('y.shape: ',y.shape)\n","y[0,:]"],"execution_count":0,"outputs":[{"output_type":"stream","text":["X shape:  (144331, 100, 1)\n","y.shape:  (144331, 45)\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n","       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)"]},"metadata":{"tags":[]},"execution_count":29}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"ZEj8EzCZq56I"},"source":["<font color=yellow  face=\"times, serif\" size=5>============================================<br>\n","Define the LSTM model using Sequential style. </font>\n"," "]},{"cell_type":"code","metadata":{"colab_type":"code","id":"9WThZ_vs2L_W","outputId":"e5ee84c1-5b9a-4755-bea2-86d3b9901c63","executionInfo":{"status":"ok","timestamp":1574968659340,"user_tz":-60,"elapsed":1467,"user":{"displayName":"Maria Brull","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAlf9Wj2cIkz8I0xIM_gnFXMx7wdLhFh3LmnxBb=s64","userId":"01827463003857096616"}},"colab":{"base_uri":"https://localhost:8080/","height":530}},"source":["# define the LSTM model\n","model = Sequential()\n","model.add(LSTM(512, input_shape=(X.shape[1], X.shape[2])))\n","model.add(Dropout(0.2))\n","model.add(Dense(y.shape[1], activation='softmax'))\n","\n","model.compile(loss='categorical_crossentropy', optimizer='adam')\n","\n","model.summary()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n","\n","Model: \"sequential_1\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","lstm_1 (LSTM)                (None, 512)               1052672   \n","_________________________________________________________________\n","dropout_1 (Dropout)          (None, 512)               0         \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 45)                23085     \n","=================================================================\n","Total params: 1,075,757\n","Trainable params: 1,075,757\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"LL5DlcUmNWpQ"},"source":["- ### Note that we not really are interested in prediction\n","- ### We are seeking a balance between generalization and overfitting but short of memorization.\n","- ### Because of the slowness of our optimization requirements, we will use model checkpointing to record all of the network weights to file each time an improvement in loss is observed at the end of the epoch.\n","- ### We will use the best set of weights (lowest loss) to instantiate our generative model in the next section."]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"epNZdoLUpVYC"},"source":["\n","\n","---\n","## SEE Keras Callbacks\n","[Keras Callbacks](https://keras.io/callbacks/)\n","\n","- A callback is a set of functions to be applied at given stages of the training procedure. \n","\n","- You can use callbacks to get a view on internal states and statistics of the model during training.\n","\n","- You can pass a list of callbacks (as the keyword argument callbacks) to the .fit() method of the Sequential or Model classes.\n","\n","- The relevant methods of the callbacks will then be called at each stage of the training. "]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"SAQkP6HauOn7"},"source":["---\n","---\n","## We will use Callbacks \"checkpoint\" to save your LSTM model into your Google Drive\n"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"fNEYAuFeuGXe","outputId":"b64f8baa-6707-43d6-8d6e-d5eab61387e5","executionInfo":{"status":"ok","timestamp":1574968717264,"user_tz":-60,"elapsed":52068,"user":{"displayName":"Maria Brull","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAlf9Wj2cIkz8I0xIM_gnFXMx7wdLhFh3LmnxBb=s64","userId":"01827463003857096616"}},"colab":{"base_uri":"https://localhost:8080/","height":189}},"source":["# MOUNT your Google Drive to save the model\n","from google.colab import drive \n","drive.mount('/content/gdrive') \n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"HjQRFIXQMyzw","colab":{}},"source":["# define the checkpoint\n","filepath=\"/content/gdrive/My Drive/weights-improvement-{epoch:02d}-{loss:.4f}.hdf5\"\n","checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n","callbacks_list = [checkpoint]"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"a9Y67_F_rn8C"},"source":["## <font color=orange> Take a look to hdf5 !!!</font>\n","\n","  HDF5 is a data model, library, and file format for storing and managing data. It supports an unlimited variety of datatypes, and is designed for flexible and efficient I/O and for high volume and complex data. HDF5 is portable and is extensible, allowing applications to evolve in their use of HDF5. The HDF5 Technology suite includes tools and applications for managing, manipulating, viewing, and analyzing data in the HDF5 format.\n","\n","## [HDF5 Web portal](https://portal.hdfgroup.org/display/HDF5/HDF5)"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"almMRAEOOQdq"},"source":["---\n","\n","## Fit our model to the data.\n","- ### Here we use a modest number of 20 epochs and a large batch size of 128 pattern"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"PWBd0kFOspoJ"},"source":["<font color=yellow  face=\"times, serif\" size=5>============================================<br>\n","**TO DO:**   Fit the model, first with 20 epochs batch_size=128 AND $callbacks$ !! </font>\n"," "]},{"cell_type":"code","metadata":{"colab_type":"code","id":"rvJOEfLBOgJ8","outputId":"a4d69e4f-eb06-41f4-ca6b-820e8f11fc68","executionInfo":{"status":"ok","timestamp":1574962206216,"user_tz":-60,"elapsed":473355,"user":{"displayName":"Maria Brull","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAlf9Wj2cIkz8I0xIM_gnFXMx7wdLhFh3LmnxBb=s64","userId":"01827463003857096616"}},"colab":{"base_uri":"https://localhost:8080/","height":686}},"source":["model.fit(X, y, epochs=200, batch_size=128, callbacks=callbacks_list)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n","\n","Epoch 1/200\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n","\n","144331/144331 [==============================] - 259s 2ms/step - loss: 2.9656\n","\n","Epoch 00001: loss improved from inf to 2.96558, saving model to /content/gdrive/My Drive/weights-improvement-01-2.9656.hdf5\n","Epoch 2/200\n","144331/144331 [==============================] - 253s 2ms/step - loss: 2.7390\n","\n","Epoch 00002: loss improved from 2.96558 to 2.73902, saving model to /content/gdrive/My Drive/weights-improvement-02-2.7390.hdf5\n","Epoch 3/200\n","144331/144331 [==============================] - 252s 2ms/step - loss: 2.6064\n","\n","Epoch 00003: loss improved from 2.73902 to 2.60642, saving model to /content/gdrive/My Drive/weights-improvement-03-2.6064.hdf5\n","Epoch 4/200\n","144331/144331 [==============================] - 252s 2ms/step - loss: 2.5034\n","\n","Epoch 00004: loss improved from 2.60642 to 2.50336, saving model to /content/gdrive/My Drive/weights-improvement-04-2.5034.hdf5\n","Epoch 5/200\n","144331/144331 [==============================] - 253s 2ms/step - loss: 2.4081\n","\n","Epoch 00005: loss improved from 2.50336 to 2.40813, saving model to /content/gdrive/My Drive/weights-improvement-05-2.4081.hdf5\n","Epoch 6/200\n","144331/144331 [==============================] - 253s 2ms/step - loss: 2.3175\n","\n","Epoch 00006: loss improved from 2.40813 to 2.31746, saving model to /content/gdrive/My Drive/weights-improvement-06-2.3175.hdf5\n","Epoch 7/200\n","144331/144331 [==============================] - 254s 2ms/step - loss: 2.2319\n","\n","Epoch 00007: loss improved from 2.31746 to 2.23189, saving model to /content/gdrive/My Drive/weights-improvement-07-2.2319.hdf5\n","Epoch 8/200\n","144331/144331 [==============================] - 254s 2ms/step - loss: 2.1456\n","\n","Epoch 00008: loss improved from 2.23189 to 2.14559, saving model to /content/gdrive/My Drive/weights-improvement-08-2.1456.hdf5\n","Epoch 9/200\n","144331/144331 [==============================] - 254s 2ms/step - loss: 2.0599\n","\n","Epoch 00009: loss improved from 2.14559 to 2.05993, saving model to /content/gdrive/My Drive/weights-improvement-09-2.0599.hdf5\n","Epoch 10/200\n","144331/144331 [==============================] - 254s 2ms/step - loss: 1.9719\n","\n","Epoch 00010: loss improved from 2.05993 to 1.97193, saving model to /content/gdrive/My Drive/weights-improvement-10-1.9719.hdf5\n","Epoch 11/200\n","144331/144331 [==============================] - 253s 2ms/step - loss: 1.8863\n","\n","Epoch 00011: loss improved from 1.97193 to 1.88634, saving model to /content/gdrive/My Drive/weights-improvement-11-1.8863.hdf5\n","Epoch 12/200\n","144331/144331 [==============================] - 253s 2ms/step - loss: 1.8063\n","\n","Epoch 00012: loss improved from 1.88634 to 1.80632, saving model to /content/gdrive/My Drive/weights-improvement-12-1.8063.hdf5\n","Epoch 13/200\n","144331/144331 [==============================] - 254s 2ms/step - loss: 1.7277\n","\n","Epoch 00013: loss improved from 1.80632 to 1.72765, saving model to /content/gdrive/My Drive/weights-improvement-13-1.7277.hdf5\n","Epoch 14/200\n","144331/144331 [==============================] - 256s 2ms/step - loss: 1.6548\n","\n","Epoch 00014: loss improved from 1.72765 to 1.65480, saving model to /content/gdrive/My Drive/weights-improvement-14-1.6548.hdf5\n","Epoch 15/200\n","144331/144331 [==============================] - 254s 2ms/step - loss: 1.5884\n","\n","Epoch 00015: loss improved from 1.65480 to 1.58845, saving model to /content/gdrive/My Drive/weights-improvement-15-1.5884.hdf5\n","Epoch 16/200\n","144331/144331 [==============================] - 255s 2ms/step - loss: 1.5233\n","\n","Epoch 00016: loss improved from 1.58845 to 1.52334, saving model to /content/gdrive/My Drive/weights-improvement-16-1.5233.hdf5\n","Epoch 17/200\n","144331/144331 [==============================] - 255s 2ms/step - loss: 1.4648\n","\n","Epoch 00017: loss improved from 1.52334 to 1.46483, saving model to /content/gdrive/My Drive/weights-improvement-17-1.4648.hdf5\n","Epoch 18/200\n","144331/144331 [==============================] - 255s 2ms/step - loss: 1.4058\n","\n","Epoch 00018: loss improved from 1.46483 to 1.40576, saving model to /content/gdrive/My Drive/weights-improvement-18-1.4058.hdf5\n","Epoch 19/200\n","144331/144331 [==============================] - 253s 2ms/step - loss: 1.3574\n","\n","Epoch 00019: loss improved from 1.40576 to 1.35737, saving model to /content/gdrive/My Drive/weights-improvement-19-1.3574.hdf5\n","Epoch 20/200\n","144331/144331 [==============================] - 254s 2ms/step - loss: 1.3067\n","\n","Epoch 00020: loss improved from 1.35737 to 1.30671, saving model to /content/gdrive/My Drive/weights-improvement-20-1.3067.hdf5\n","Epoch 21/200\n","144331/144331 [==============================] - 253s 2ms/step - loss: 1.2695\n","\n","Epoch 00021: loss improved from 1.30671 to 1.26946, saving model to /content/gdrive/My Drive/weights-improvement-21-1.2695.hdf5\n","Epoch 22/200\n","144331/144331 [==============================] - 254s 2ms/step - loss: 1.2270\n","\n","Epoch 00022: loss improved from 1.26946 to 1.22704, saving model to /content/gdrive/My Drive/weights-improvement-22-1.2270.hdf5\n","Epoch 23/200\n","144331/144331 [==============================] - 252s 2ms/step - loss: 1.1934\n","\n","Epoch 00023: loss improved from 1.22704 to 1.19342, saving model to /content/gdrive/My Drive/weights-improvement-23-1.1934.hdf5\n","Epoch 24/200\n","144331/144331 [==============================] - 254s 2ms/step - loss: 1.1539\n","\n","Epoch 00024: loss improved from 1.19342 to 1.15390, saving model to /content/gdrive/My Drive/weights-improvement-24-1.1539.hdf5\n","Epoch 25/200\n","144331/144331 [==============================] - 257s 2ms/step - loss: 1.1230\n","\n","Epoch 00025: loss improved from 1.15390 to 1.12302, saving model to /content/gdrive/My Drive/weights-improvement-25-1.1230.hdf5\n","Epoch 26/200\n","144331/144331 [==============================] - 254s 2ms/step - loss: 1.0991\n","\n","Epoch 00026: loss improved from 1.12302 to 1.09908, saving model to /content/gdrive/My Drive/weights-improvement-26-1.0991.hdf5\n","Epoch 27/200\n","144331/144331 [==============================] - 255s 2ms/step - loss: 1.0676\n","\n","Epoch 00027: loss improved from 1.09908 to 1.06761, saving model to /content/gdrive/My Drive/weights-improvement-27-1.0676.hdf5\n","Epoch 28/200\n","144331/144331 [==============================] - 254s 2ms/step - loss: 1.0433\n","\n","Epoch 00028: loss improved from 1.06761 to 1.04333, saving model to /content/gdrive/My Drive/weights-improvement-28-1.0433.hdf5\n","Epoch 29/200\n","144331/144331 [==============================] - 254s 2ms/step - loss: 1.0141\n","\n","Epoch 00029: loss improved from 1.04333 to 1.01411, saving model to /content/gdrive/My Drive/weights-improvement-29-1.0141.hdf5\n","Epoch 30/200\n","144331/144331 [==============================] - 254s 2ms/step - loss: 0.9920\n","\n","Epoch 00030: loss improved from 1.01411 to 0.99200, saving model to /content/gdrive/My Drive/weights-improvement-30-0.9920.hdf5\n","Epoch 31/200\n","144331/144331 [==============================] - 254s 2ms/step - loss: 0.9748\n","\n","Epoch 00031: loss improved from 0.99200 to 0.97478, saving model to /content/gdrive/My Drive/weights-improvement-31-0.9748.hdf5\n","Epoch 32/200\n","144331/144331 [==============================] - 254s 2ms/step - loss: 0.9552\n","\n","Epoch 00032: loss improved from 0.97478 to 0.95521, saving model to /content/gdrive/My Drive/weights-improvement-32-0.9552.hdf5\n","Epoch 33/200\n","144331/144331 [==============================] - 255s 2ms/step - loss: 0.9359\n","\n","Epoch 00033: loss improved from 0.95521 to 0.93588, saving model to /content/gdrive/My Drive/weights-improvement-33-0.9359.hdf5\n","Epoch 34/200\n","144331/144331 [==============================] - 254s 2ms/step - loss: 0.9121\n","\n","Epoch 00034: loss improved from 0.93588 to 0.91214, saving model to /content/gdrive/My Drive/weights-improvement-34-0.9121.hdf5\n","Epoch 35/200\n","144331/144331 [==============================] - 259s 2ms/step - loss: 0.8982\n","\n","Epoch 00035: loss improved from 0.91214 to 0.89817, saving model to /content/gdrive/My Drive/weights-improvement-35-0.8982.hdf5\n","Epoch 36/200\n","144331/144331 [==============================] - 258s 2ms/step - loss: 0.8875\n","\n","Epoch 00036: loss improved from 0.89817 to 0.88748, saving model to /content/gdrive/My Drive/weights-improvement-36-0.8875.hdf5\n","Epoch 37/200\n","144331/144331 [==============================] - 263s 2ms/step - loss: 0.8683\n","\n","Epoch 00037: loss improved from 0.88748 to 0.86829, saving model to /content/gdrive/My Drive/weights-improvement-37-0.8683.hdf5\n","Epoch 38/200\n","144331/144331 [==============================] - 258s 2ms/step - loss: 0.8511\n","\n","Epoch 00038: loss improved from 0.86829 to 0.85108, saving model to /content/gdrive/My Drive/weights-improvement-38-0.8511.hdf5\n","Epoch 39/200\n","144331/144331 [==============================] - 254s 2ms/step - loss: 0.8383\n","\n","Epoch 00039: loss improved from 0.85108 to 0.83832, saving model to /content/gdrive/My Drive/weights-improvement-39-0.8383.hdf5\n","Epoch 40/200\n","144331/144331 [==============================] - 258s 2ms/step - loss: 0.8285\n","\n","Epoch 00040: loss improved from 0.83832 to 0.82848, saving model to /content/gdrive/My Drive/weights-improvement-40-0.8285.hdf5\n","Epoch 41/200\n","144331/144331 [==============================] - 264s 2ms/step - loss: 0.8107\n","\n","Epoch 00041: loss improved from 0.82848 to 0.81074, saving model to /content/gdrive/My Drive/weights-improvement-41-0.8107.hdf5\n","Epoch 42/200\n","144331/144331 [==============================] - 258s 2ms/step - loss: 0.8002\n","\n","Epoch 00042: loss improved from 0.81074 to 0.80016, saving model to /content/gdrive/My Drive/weights-improvement-42-0.8002.hdf5\n","Epoch 43/200\n","144331/144331 [==============================] - 253s 2ms/step - loss: 0.7918\n","\n","Epoch 00043: loss improved from 0.80016 to 0.79182, saving model to /content/gdrive/My Drive/weights-improvement-43-0.7918.hdf5\n","Epoch 44/200\n","144331/144331 [==============================] - 256s 2ms/step - loss: 0.7894\n","\n","Epoch 00044: loss improved from 0.79182 to 0.78941, saving model to /content/gdrive/My Drive/weights-improvement-44-0.7894.hdf5\n","Epoch 45/200\n","144331/144331 [==============================] - 256s 2ms/step - loss: 0.7608\n","\n","Epoch 00045: loss improved from 0.78941 to 0.76081, saving model to /content/gdrive/My Drive/weights-improvement-45-0.7608.hdf5\n","Epoch 46/200\n","144331/144331 [==============================] - 251s 2ms/step - loss: 0.7487\n","\n","Epoch 00046: loss improved from 0.76081 to 0.74868, saving model to /content/gdrive/My Drive/weights-improvement-46-0.7487.hdf5\n","Epoch 47/200\n","144331/144331 [==============================] - 265s 2ms/step - loss: 0.7464\n","\n","Epoch 00047: loss improved from 0.74868 to 0.74636, saving model to /content/gdrive/My Drive/weights-improvement-47-0.7464.hdf5\n","Epoch 48/200\n","144331/144331 [==============================] - 258s 2ms/step - loss: 0.7375\n","\n","Epoch 00048: loss improved from 0.74636 to 0.73752, saving model to /content/gdrive/My Drive/weights-improvement-48-0.7375.hdf5\n","Epoch 49/200\n","144331/144331 [==============================] - 250s 2ms/step - loss: 0.7294\n","\n","Epoch 00049: loss improved from 0.73752 to 0.72940, saving model to /content/gdrive/My Drive/weights-improvement-49-0.7294.hdf5\n","Epoch 50/200\n","144331/144331 [==============================] - 266s 2ms/step - loss: 0.7125\n","\n","Epoch 00050: loss improved from 0.72940 to 0.71249, saving model to /content/gdrive/My Drive/weights-improvement-50-0.7125.hdf5\n","Epoch 51/200\n","144331/144331 [==============================] - 251s 2ms/step - loss: 0.7122\n","\n","Epoch 00051: loss improved from 0.71249 to 0.71219, saving model to /content/gdrive/My Drive/weights-improvement-51-0.7122.hdf5\n","Epoch 52/200\n","144331/144331 [==============================] - 250s 2ms/step - loss: 0.7029\n","\n","Epoch 00052: loss improved from 0.71219 to 0.70287, saving model to /content/gdrive/My Drive/weights-improvement-52-0.7029.hdf5\n","Epoch 53/200\n"," 26752/144331 [====>.........................] - ETA: 3:23 - loss: 0.6276"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"mBbvECurEf75","colab_type":"code","outputId":"9ee35d28-2473-4998-de6b-e97fe9e5c5c4","executionInfo":{"status":"error","timestamp":1574962589895,"user_tz":-60,"elapsed":246544,"user":{"displayName":"Maria Brull","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAlf9Wj2cIkz8I0xIM_gnFXMx7wdLhFh3LmnxBb=s64","userId":"01827463003857096616"}},"colab":{"base_uri":"https://localhost:8080/","height":375}},"source":["model.fit(X, y, epochs=2, batch_size=128)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Epoch 1/2\n","144331/144331 [==============================] - 239s 2ms/step - loss: 2.6481\n","Epoch 2/2\n","  3712/144331 [..............................] - ETA: 3:48 - loss: 2.5961"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-38-44b78127eadf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1176\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1178\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m     def evaluate(self,\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    202\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2977\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2978\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2979\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2980\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2981\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2935\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2936\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2937\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2938\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2939\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"u1L1Isk0tAUs"},"source":["## check that callbacks has stored best models"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"dut9u1dCU4_8","outputId":"a4e5d8ab-c416-4d43-a1b2-b8172f7e8483","executionInfo":{"status":"ok","timestamp":1574962210118,"user_tz":-60,"elapsed":3860,"user":{"displayName":"Maria Brull","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAlf9Wj2cIkz8I0xIM_gnFXMx7wdLhFh3LmnxBb=s64","userId":"01827463003857096616"}},"colab":{"base_uri":"https://localhost:8080/","height":233}},"source":["ls /content/gdrive/'My Drive'"],"execution_count":0,"outputs":[{"output_type":"stream","text":[" \u001b[0m\u001b[01;34mAPMICRO\u001b[0m/                         \u001b[01;34mOSA-python\u001b[0m/\n","'Carta mama.gdoc'                 \u001b[01;34mpreguntas\u001b[0m/\n","\u001b[01;34m'Colab Notebooks'\u001b[0m/               \u001b[01;34m'Proyecto: HOP IN'\u001b[0m/\n"," \u001b[01;34menglish\u001b[0m/                         \u001b[01;34mRECM-SCOM\u001b[0m/\n"," \u001b[01;34mGPRO-PROJECT\u001b[0m/                    \u001b[01;34mSSMM\u001b[0m/\n","'Guided Tour VALENCIA.pdf'        Sw.zip\n"," Info_BDApnea_QuironMalaga.xlsx   \u001b[01;34mtfg\u001b[0m/\n","\u001b[01;34m'ISIN '\u001b[0m/                          \u001b[01;34mVodafone\u001b[0m/\n"," L3_MariaBrull.zip                weights-improvement-01-2.9259.hdf5\n"," \u001b[01;34mMANU-MARIA\u001b[0m/                      weights-improvement-02-2.7426.hdf5\n"," Material_L2.zip\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"b56na_XOgENd","colab":{}},"source":["! cp /content/gdrive/'My Drive'/weights-improvement-02-2.7426.hdf5 weights.hdf5"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"PSHIipg-O8Cq"},"source":["\n","\n","---\n","\n","## Generating Text with an LSTM Network"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"BgfgxAWcO0Jk"},"source":["\n","---\n","\n","## The network weights are loaded from a checkpoint file and the network does not need to be trained."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"9ZLq6SOWPMTK","colab":{}},"source":["# load the network weights\n","filename = \"weights.hdf5\"\n","model.load_weights(filename)\n","model.compile(loss='categorical_crossentropy', optimizer='adam')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"zesHff1Q2E6e"},"source":["---\n","\n","## Finally: make predictions.\n","\n","- ### The simplest way is to first start with a seed sequence as input and predict the next character\n","- ### then update the seed sequence to add the predicted character on the end and trim off the first character.\n","- ### ...repeat this process to predict new characters (e.g. a sequence of 1,000 characters in length).\n"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"NtHbjyJlQqbE","outputId":"13c2d616-73d7-4d59-99da-abe780cee6fd","executionInfo":{"status":"ok","timestamp":1574963192014,"user_tz":-60,"elapsed":42822,"user":{"displayName":"Maria Brull","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAlf9Wj2cIkz8I0xIM_gnFXMx7wdLhFh3LmnxBb=s64","userId":"01827463003857096616"}},"colab":{"base_uri":"https://localhost:8080/","height":357}},"source":["import sys\n","\n","#pick a random seed\n","start = np.random.randint(0, len(dataX)-1)\n","pattern = dataX[start]\n","print(\"Seed:\")\n","print(\"\\\"\", ''.join([int_to_char[value] for value in pattern]), \"\\\"\")\n","print('\\n GENERATE: \\n')\n","\n","# generate characters\n","for i in range(500):\n","  x = np.reshape(pattern, (1, len(pattern), 1))\n","  x = x / float(n_vocab)\n","  prediction = model.predict(x, verbose=0)\n","  index = np.argmax(prediction)\n","  result = int_to_char[index]\n"," \n","  #print every ouput character\n","  sys.stdout.write(result)\n","  \n","  # add output char\n","  pattern.append(index)\n","  # remove first char\n","  pattern = pattern[1:len(pattern)]\n","  \n","print(\"\\nDone.\")"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Seed:\n","\" at the great concert\n","given by the queen of hearts, and i had to sing\n","\n","     \"twinkle, twinkle, little \"\n","\n"," GENERATE: \n","\n"," toe toet to the toee  \n","nhe tae haree to the toree  \n","nhe toet ho the  and the toet toe toee th the woee  \n","nhe toet ho the  and the toet toe toee th the woee  \n","nhe toet ho the  and the toet toe toee th the woee  \n","nhe toet ho the  and the toet toe toee th the woee  \n","nhe toet ho the  and the toet toe toee th the woee  \n","nhe toet ho the  and the toet toe toee th the woee  \n","nhe toet ho the  and the toet toe toee th the woee  \n","nhe toet ho the  and the toet toe toee th the woee  \n","nhe toet ho the  and th\n","Done.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"BjSJJA6OVnkK","outputId":"78a7cce3-c752-4329-a981-800ba78d4e52","executionInfo":{"status":"ok","timestamp":1574962684380,"user_tz":-60,"elapsed":2131,"user":{"displayName":"Maria Brull","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAlf9Wj2cIkz8I0xIM_gnFXMx7wdLhFh3LmnxBb=s64","userId":"01827463003857096616"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["result"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'o'"]},"metadata":{"tags":[]},"execution_count":40}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"nO2Tbo852E6g"},"source":["# You can look for some ideas and improvements in:\n","\n","- ### [Learn about EMBEDDINGS](https://github.com/fchollet/deep-learning-with-python-notebooks/blob/master/6.1-using-word-embeddings.ipynb)\n","\n","- ### [text-generation-lstm-recurrent-neural-networks-python-keras](https://machinelearningmastery.com/text-generation-lstm-recurrent-neural-networks-python-keras/)\n","\n","- ### [Deepanway Ghosal](https://github.com/deepanwayx/char-and-word-rnn-keras)\n","\n"]}]}